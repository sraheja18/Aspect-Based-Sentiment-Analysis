{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "399cf507-5025-4fc7-8f11-67c4b0ba3ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model.bert import bert_ATE, bert_ABSA\n",
    "from transformers import BertTokenizer\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "280191d4-ef83-4a1b-b863-a3ad8658b31f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"mps\" if torch.has_mps else \"cpu\")\n",
    "pretrain_model_name = \"bert-base-uncased\"\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrain_model_name)\n",
    "lr = 2e-5\n",
    "model_ATE = bert_ATE(pretrain_model_name).to(DEVICE)\n",
    "optimizer_ATE = torch.optim.Adam(model_ATE.parameters(), lr=lr)\n",
    "model_ABSA = bert_ABSA(pretrain_model_name).to(DEVICE)\n",
    "optimizer_ABSA = torch.optim.Adam(model_ABSA.parameters(), lr=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40693709-52bc-4394-acac-63b374a70488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, path):\n",
    "    model.load_state_dict(torch.load(path), strict=False)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f863a7d-9d17-4ca3-a518-0efee4fe653d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ATE = load_model(model_ATE, 'bert_ATE.pkl')\n",
    "model_ABSA = load_model(model_ABSA, 'bert_ABSA.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4dc34e12-6871-4c76-8525-1cf4641e2728",
   "metadata": {},
   "outputs": [],
   "source": [
    "polarities = {0:\"Negative\", 1:\"Neutral\", 2:\"Positive\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0134bcc7-a5ae-4281-908a-52467dd8f535",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_ATE(sentence, tokenizer):\n",
    "    word_pieces = []\n",
    "    tokens = tokenizer.tokenize(sentence)\n",
    "    word_pieces += tokens\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ATE(input_tensor, None, None)\n",
    "        _, predictions = torch.max(outputs, dim=2)\n",
    "    predictions = predictions[0].tolist()\n",
    "\n",
    "    return word_pieces, predictions, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "690026b7-d53c-4166-883c-124a9c042865",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_model_ABSA(sentence, aspect, tokenizer):\n",
    "    t1 = tokenizer.tokenize(sentence)\n",
    "    t2 = tokenizer.tokenize(aspect)\n",
    "\n",
    "    word_pieces = ['[cls]']\n",
    "    word_pieces += t1\n",
    "    word_pieces += ['[sep]']\n",
    "    word_pieces += t2\n",
    "\n",
    "    segment_tensor = [0] + [0]*len(t1) + [0] + [1]*len(t2)\n",
    "\n",
    "    ids = tokenizer.convert_tokens_to_ids(word_pieces)\n",
    "    input_tensor = torch.tensor([ids]).to(DEVICE)\n",
    "    segment_tensor = torch.tensor(segment_tensor).to(DEVICE)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model_ABSA(input_tensor, None, None, segments_tensors=segment_tensor)\n",
    "        outputs = torch.softmax(outputs, dim=1)\n",
    "        _,predictions = torch.max(outputs,dim=1)\n",
    "    \n",
    "    return word_pieces, predictions, outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "fd96593b-8bce-4fb0-a65e-78f3a78512cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ATE_ABSA(text):\n",
    "    terms = []\n",
    "    word = \"\"\n",
    "    x, y, z = predict_model_ATE(text, tokenizer)\n",
    "    for i in range(len(y)):\n",
    "        if y[i] == 1:\n",
    "            if len(word) != 0:\n",
    "                terms.append(word.replace(\" ##\",\"\"))\n",
    "            word = x[i]\n",
    "        if y[i] == 2:\n",
    "            word += (\" \" + x[i])\n",
    "            \n",
    "    \n",
    "    if len(word) != 0:\n",
    "            terms.append(word.replace(\" ##\",\"\"))\n",
    "            \n",
    "    print(\"Aspects:\", terms)\n",
    "    \n",
    "    if len(terms) != 0:\n",
    "        for i in terms:\n",
    "            _, c, p = predict_model_ABSA(text, i, tokenizer)\n",
    "            print(\"Term:\", i, \", Class:\", polarities[int(c)], \", Probability:\", round(float(p[0][int(c)]),3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f76a958f-df37-4c33-a963-5082269c10dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspects: ['price', 'battery life']\n",
      "Term: price , Class: Positive , Probability: 0.914\n",
      "Term: battery life , Class: Negative , Probability: 0.999\n"
     ]
    }
   ],
   "source": [
    "text = \"For the price you pay, this product is very good. However, battery life is a little lack-luster coming from a MacBook Pro.\"\n",
    "ATE_ABSA(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0e5df374-0f89-4eba-9540-62aafb6ec984",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aspects: ['speakers', 'screen colors']\n",
      "Term: ['speakers'] , Class: Positive , Probability: 0.999\n",
      "Term: ['screen colors'] , Class: Negative , Probability: 1.0\n"
     ]
    }
   ],
   "source": [
    "text = \"Speakers are great but screen colors are dull.\"\n",
    "ATE_ABSA(text)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
